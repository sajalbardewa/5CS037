{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sajalbardewa/5CS037/blob/main/worksheet7AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_zuS6Yqx0-A"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, LogisticRegression\n",
        "from sklearn.metrics import mean_squared_error, accuracy_score\n",
        "from sklearn.datasets import fetch_california_housing, load_breast_cancer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "X, y = fetch_california_housing(return_X_y=True, download_if_missing=False)\n",
        "\n",
        "# Split into training (80%) and test (20%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "j9iVMhJWzorp",
        "outputId": "d4ee696e-64f0-4084-8426-614d288c8fd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "Data not found and `download_if_missing` is False",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1267880658.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_california_housing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturn_X_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_if_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Split into training (80%) and test (20%) sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/datasets/_california_housing.py\u001b[0m in \u001b[0;36mfetch_california_housing\u001b[0;34m(data_home, download_if_missing, return_X_y, as_frame, n_retries, delay)\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdownload_if_missing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Data not found and `download_if_missing` is False\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         logger.info(\n",
            "\u001b[0;31mOSError\u001b[0m: Data not found and `download_if_missing` is False"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train baseline model\n",
        "base_reg = LinearRegression()\n",
        "base_reg.fit(X_train, y_train)\n",
        "\n",
        "# Predict and compute MSE\n",
        "train_mse = mean_squared_error(y_train, base_reg.predict(X_train))\n",
        "test_mse = mean_squared_error(y_test, base_reg.predict(X_test))\n",
        "\n",
        "print(f\"Baseline Train MSE: {train_mse}\")\n",
        "print(f\"Baseline Test MSE: {test_mse}\")\n",
        "print(f\"Baseline Coefficients: {base_reg.coef_}\")"
      ],
      "metadata": {
        "id": "ZZSi72gwzqLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define alpha grid\n",
        "param_grid = {'alpha': [0.01, 0.1, 1, 10, 100]}\n",
        "\n",
        "# Tune Ridge (L2)\n",
        "ridge_cv = GridSearchCV(Ridge(), param_grid, cv=5)\n",
        "ridge_cv.fit(X_train, y_train)\n",
        "\n",
        "# Tune Lasso (L1)\n",
        "lasso_cv = GridSearchCV(Lasso(), param_grid, cv=5)\n",
        "lasso_cv.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best Ridge Alpha: {ridge_cv.best_params_}\")\n",
        "print(f\"Best Lasso Alpha: {lasso_cv.best_params_}\") [5]\n"
      ],
      "metadata": {
        "id": "NoRqLghmzuYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train with best alphas\n",
        "best_ridge = ridge_cv.best_estimator_\n",
        "best_lasso = lasso_cv.best_estimator_\n"
      ],
      "metadata": {
        "id": "l3pFlEdEz0FU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train with best alphas\n",
        "best_ridge = ridge_cv.best_estimator_\n",
        "best_lasso = lasso_cv.best_estimator_\n",
        "\n",
        "# Compare coefficients\n",
        "print(f\"Ridge Coefficients: {best_ridge.coef_}\")\n",
        "print(f\"Lasso Coefficients (Note zeros/sparsity): {best_lasso.coef_}\") [6]\n",
        "\n",
        "# Evaluate MSE\n",
        "print(f\"Ridge Test MSE: {mean_squared_error(y_test, best_ridge.predict(X_test))}\")\n",
        "print(f\"Lasso Test MSE: {mean_squared_error(y_test, best_lasso.predict(X_test))}\") [6]"
      ],
      "metadata": {
        "id": "PfhnSZdbz2kt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "X_c, y_c = load_breast_cancer(return_X_y=True)\n",
        "\n",
        "# Split 80/20\n",
        "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(X_c, y_c, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "bdcxvYpnz_2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Baseline Logistic Regression\n",
        "base_clf = LogisticRegression(max_iter=10000) # Increased max_iter for convergence\n",
        "base_clf.fit(X_train_c, y_train_c)\n",
        "\n",
        "# Accuracy\n",
        "train_acc = accuracy_score(y_train_c, base_clf.predict(X_train_c))\n",
        "test_acc = accuracy_score(y_test_c, base_clf.predict(X_test_c))\n",
        "\n",
        "print(f\"Baseline Train Accuracy: {train_acc}\")\n",
        "print(f\"Baseline Test Accuracy: {test_acc}\") [8, 9]"
      ],
      "metadata": {
        "id": "XgYxla3g0GuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Grid for Logistic Regression (Note: 'liblinear' solver supports both l1 and l2)\n",
        "clf_param_grid = {'C': [0.01, 0.1, 1, 10, 100], 'penalty': ['l1', 'l2']}\n",
        "\n",
        "clf_cv = GridSearchCV(LogisticRegression(solver='liblinear'), clf_param_grid, cv=5)\n",
        "clf_cv.fit(X_train_c, y_train_c)\n",
        "\n",
        "print(f\"Best Classification Params: {clf_cv.best_params_}\") [9, 10]"
      ],
      "metadata": {
        "id": "vNabhp1k0Iyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train L1 and L2 specifically with best C\n",
        "best_C = clf_cv.best_params_['C']\n",
        "l1_model = LogisticRegression(penalty='l1', C=best_C, solver='liblinear').fit(X_train_c, y_train_c)\n",
        "l2_model = LogisticRegression(penalty='l2', C=best_C, solver='liblinear').fit(X_train_c, y_train_c)\n",
        "\n",
        "# Compare sparsity\n",
        "print(f\"L1 Sparse Coeffs: {l1_model.coef_}\")\n",
        "print(f\"L2 Shrunken Coeffs: {l2_model.coef_}\") [10]\n",
        "\n",
        "# Accuracy comparison\n",
        "print(f\"L1 Test Accuracy: {accuracy_score(y_test_c, l1_model.predict(X_test_c))}\")\n",
        "print(f\"L2 Test Accuracy: {accuracy_score(y_test_c, l2_model.predict(X_test_c))}\") [11]"
      ],
      "metadata": {
        "id": "KLqbXA5M0L28"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}